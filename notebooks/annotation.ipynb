{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad19178",
   "metadata": {},
   "source": [
    "# Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5cdcb5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dba5cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be979324",
   "metadata": {},
   "source": [
    "## Performance de la labelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced81120",
   "metadata": {},
   "source": [
    "### Retrieve doccano labelling\n",
    "\n",
    "first import doccano labels from web interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "88524d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def retrieve_labelling(json_file):\n",
    "    ret = pd.DataFrame(json.load(open(json_file))).set_index(\"id\")\n",
    "    ret.label = ret.label.apply(lambda x: x[0] if len(x)>0 else None)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e41a8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/Users/charlesprat/Downloads/03d3a4cf-165c-41a9-8650-b3ecdbfe00dd\"\n",
    "amir = retrieve_labelling(os.path.join(root_path,\"yotta-amir.json\"))\n",
    "charles = retrieve_labelling(os.path.join(root_path,\"yotta-charles-henri.json\"))\n",
    "moindze = retrieve_labelling(os.path.join(root_path,\"yotta-moindze.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "81d32c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = moindze.join(amir.label.rename(\"amir\")).join(charles.label.rename(\"charles\")).rename(\n",
    "    columns={\"label\": \"moindze\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "13738f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm.to_csv(\"labels_merge.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c1f94",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "946fe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f173040d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_db95b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_db95b_level0_col0\" class=\"col_heading level0 col0\" >accuracy</th>\n",
       "      <th id=\"T_db95b_level0_col1\" class=\"col_heading level0 col1\" >rendement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_db95b_level0_row0\" class=\"row_heading level0 row0\" >('moindze', 'amir')</th>\n",
       "      <td id=\"T_db95b_row0_col0\" class=\"data row0 col0\" >0.75</td>\n",
       "      <td id=\"T_db95b_row0_col1\" class=\"data row0 col1\" >0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db95b_level0_row1\" class=\"row_heading level0 row1\" >('moindze', 'charles')</th>\n",
       "      <td id=\"T_db95b_row1_col0\" class=\"data row1 col0\" >0.73</td>\n",
       "      <td id=\"T_db95b_row1_col1\" class=\"data row1 col1\" >0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db95b_level0_row2\" class=\"row_heading level0 row2\" >('amir', 'charles')</th>\n",
       "      <td id=\"T_db95b_row2_col0\" class=\"data row2 col0\" >0.70</td>\n",
       "      <td id=\"T_db95b_row2_col1\" class=\"data row2 col1\" >0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f87613990d0>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label_v1 = pd.read_csv(\"../data/labels_v1.csv\")\n",
    "label_v1 = pd.read_csv(\"labels_merge.csv\")\n",
    "\n",
    "def compute_accuracy(v1,v2):\n",
    "    drop_val = (v1 == \"inclassable\") | (v2==\"inclassable\")\n",
    "    annotation_yield = 1-drop_val.mean()\n",
    "    return accuracy_score(v1[~drop_val], v2[~drop_val]), annotation_yield\n",
    "\n",
    "annotators = [(\"moindze\", \"amir\"), (\"moindze\", \"charles\"), (\"amir\", \"charles\")]\n",
    "\n",
    "pd.DataFrame([compute_accuracy(label_v1[an1], label_v1[an2]) \n",
    "              for an1,an2 in annotators], \n",
    "             columns=[\"accuracy\", \"rendement\"],\n",
    "             index=[(an1,an2) for an1, an2 in annotators]\n",
    "            ).style.format(precision=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f3c19",
   "metadata": {},
   "source": [
    "## Generation d'un set de labellisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b4462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:answers.csv imported on the disk\n"
     ]
    }
   ],
   "source": [
    "from dissidentia.infrastructure.grand_debat import GDAnswers\n",
    "\n",
    "answs = GDAnswers().load_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddb1fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(\"\\.+\", \".\", text)\n",
    "    test = re.sub(r\"\\.([A-Z])\", r\". \\1\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e742e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 772/772 [00:00<00:00, 9077.13it/s]\n",
      "/Users/charlesprat/miniconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "sentences = np.sum([tokenize.sent_tokenize(preprocess(ans)) for ans in tqdm(answs)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8a8485d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2515"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb22dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6441393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 20:49:28.503740: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e81c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01940380927408114"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "test_sentence = \"c'est archi nul !\"\n",
    "\n",
    "def predict_huggingface(test_sentence):\n",
    "    inputs = tokenizer(test_sentence, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            logits = model(**inputs).logits\n",
    "        except:\n",
    "            return -1\n",
    "        \n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    softmaxFunc = torch.nn.Softmax(dim=1)\n",
    "    softmaxScores = softmaxFunc(logits)\n",
    "    probas = softmaxScores[0].detach().numpy()\n",
    "    \n",
    "    return np.sum(probas * np.arange(5)) / 4\n",
    "\n",
    "predict_huggingface(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d60f2a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 2515/2515 [03:40<00:00, 11.41it/s]\n"
     ]
    }
   ],
   "source": [
    "hf_predict = [predict_huggingface(sentence) for sentence in tqdm(sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a00ea71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gd = pd.DataFrame({\"sentences\": sentences, \"hf_pred\": hf_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ae793971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gd.sort_values(by=\"hf_pred\").sentences.iloc[100:200].rename(\"text\").to_csv(\"second_ds.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
